{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_years = [\n",
    "    '201617', '201718','201819'\n",
    "]\n",
    "train_years = [\n",
    "    '200001','200102', '200203', '200304', '200405', '200506', '200607', '200708', '200809', '200910',\n",
    "    '201011', '201112', '201213','201314', '201415','201516'\n",
    "]\n",
    "selected = 1\n",
    "\n",
    "# private method used in sortAllGamesBySeed\n",
    "def swap(row):   \n",
    "    d = {\n",
    "        'season': [row.pop('season')],\n",
    "        'teamAName': [row.pop('teamBName')],\n",
    "        'teamASeed': [row.pop('teamBSeed')],\n",
    "        'teamBName': [row.pop('teamAName')],\n",
    "        'teamBSeed': [row.pop('teamASeed')],\n",
    "    }\n",
    "    updated_row = pd.DataFrame(data=d)\n",
    "    return updated_row\n",
    "    \n",
    "# left = higherSeed, right = lowerSeed\n",
    "def sortAllGamesBySeed(year):\n",
    "    playoff_data = pd.read_csv(\"./data/playoff/playoffdata\" + year + \".csv\")\n",
    "\n",
    "    ## Swap columns so higher seed (lower value) on the left, lower seed (higher value) on the right\n",
    "    updated_data = playoff_data.copy()\n",
    "    updated_data.columns = ['season', 'teamAName', 'teamASeed', 'teamBName', 'teamBSeed']\n",
    "    for index, row in updated_data.iterrows():\n",
    "        if row['teamASeed'] > row['teamBSeed']:\n",
    "            updated_data.loc[index,['teamAName', 'teamBName']] = updated_data.loc[index,['teamBName', 'teamAName']].values\n",
    "            updated_data.loc[index,['teamASeed', 'teamBSeed']] = updated_data.loc[index,['teamBSeed', 'teamASeed']].values\n",
    "    return updated_data\n",
    "\n",
    "\n",
    "# break down the bracket into rounds\n",
    "def breakdownBracket(updated_data):\n",
    "    first_round = None\n",
    "    second_round = None\n",
    "    third_round = None\n",
    "    fourth_round = None\n",
    "    semi_final = updated_data.iloc[60 : 62]\n",
    "    final = updated_data.iloc[62 : 63]\n",
    "    for region_index in range(0, 60, 15): \n",
    "        first = updated_data.iloc[region_index : region_index + 8]\n",
    "        first_round = first if first_round is None else pd.concat([first_round, first])\n",
    "\n",
    "        second = updated_data.iloc[region_index + 8 : region_index + 12, :]  \n",
    "        second_round = second if second_round is None else pd.concat([second_round, second])\n",
    "\n",
    "        third = updated_data.iloc[region_index + 12 : region_index + 14]\n",
    "        third_round = third if third_round is None else pd.concat([third_round, third])\n",
    "\n",
    "        fourth = updated_data.iloc[region_index + 14 : region_index + 15]\n",
    "        fourth_round = fourth if fourth_round is None else pd.concat([fourth_round, fourth])\n",
    "    return first_round, second_round, third_round, fourth_round, semi_final, final\n",
    "\n",
    "\n",
    "def swapGames(playoff_data):\n",
    "#     playoff_data = pd.read_csv(\"./data/playoff/playoffdata\" + year + \".csv\")\n",
    "\n",
    "    ## Swap columns so higher seed (lower value) on the left, lower seed (higher value) on the right\n",
    "    updated_data = playoff_data.copy()\n",
    "    updated_data.columns = ['season', 'teamAName', 'teamASeed', 'teamBName', 'teamBSeed']\n",
    "    for index, row in updated_data.iterrows():\n",
    "        if row['teamASeed'] > row['teamBSeed']:\n",
    "            updated_data.loc[index,['teamAName', 'teamBName']] = updated_data.loc[index,['teamBName', 'teamAName']].values\n",
    "            updated_data.loc[index,['teamASeed', 'teamBSeed']] = updated_data.loc[index,['teamBSeed', 'teamASeed']].values\n",
    "    return updated_data\n",
    "\n",
    "def calculateLabels(year, games):\n",
    "    playoff_results = pd.read_csv(\"./data/playoff/playoffdata\" + year + \".csv\")\n",
    "    winner_names = playoff_results['winnerName']\n",
    "    labels = winner_names.copy()\n",
    "    for index, row in games.iterrows():\n",
    "        if row['teamAName'] == winner_names.loc[index]:\n",
    "            labels.loc[index] = 1\n",
    "        else:\n",
    "            labels.loc[index] = 0\n",
    "    return labels.to_frame()\n",
    "\n",
    "\n",
    "def compareTeams(team_a_info, team_b_info):\n",
    "    if len(team_a_info.columns) == len(team_b_info.columns):\n",
    "        diff = team_a_info.copy()\n",
    "        for col in team_a_info.columns:\n",
    "            diff[col] = team_a_info[col].values - team_b_info[col].values\n",
    "        return diff\n",
    "    else: \n",
    "        print(\"Team A column length: \", len(team_A.columns))\n",
    "        print(\"Team B column length: \", len(team_B.columns))\n",
    "        print(\"Something is wrong in the data\")\n",
    "        return None\n",
    "\n",
    "    # find difference between two teams' stats\n",
    "def compareTeamsByName(teamAName, teamBName, year):\n",
    "    team_A = getTeamDataByYear(year, teamAName)\n",
    "    team_B = getTeamDataByYear(year, teamBName)\n",
    "    if len(team_A.columns) == len(team_B.columns):\n",
    "        diff = team_A.copy()\n",
    "        for col in team_A.columns:\n",
    "            diff[col] = team_A[col].values[0] - team_B[col].values[0]\n",
    "        return diff\n",
    "    else: \n",
    "        print(\"Team A column length: \", len(team_A.columns))\n",
    "        print(\"Team B column length: \", len(team_B.columns))\n",
    "        print(\"Something is wrong in the data\")\n",
    "        return None\n",
    "\n",
    "def getTeamInfos(teamA, teamB, year):\n",
    "    data = pd.read_excel(io=\"./data/formatted/basic/basicdata\" + year + \".xlsx\")\n",
    "    team_basic_data = data.copy()\n",
    "    \n",
    "    team_a = teamA.copy()\n",
    "    team_b = teamB.copy()\n",
    "\n",
    "    team_a = team_a.merge(team_basic_data, left_on='teamAName', right_on='School', how='left')\n",
    "    team_a = team_a.rename(columns={\"teamASeed\": \"seed\"})\n",
    "    team_a.drop('teamAName', axis=1, inplace=True)\n",
    "#     team_a.drop('teamASeed', axis=1, inplace=True)\n",
    "    team_a.drop('School', axis=1, inplace=True)\n",
    "    team_a.drop('ID', axis=1, inplace=True)\n",
    "    team_a.drop('PersonalFouls', axis=1, inplace=True)\n",
    "\n",
    "    team_b = team_b.merge(team_basic_data, left_on='teamBName', right_on='School', how='left')\n",
    "    team_b = team_b.rename(columns={\"teamBSeed\": \"seed\"})\n",
    "    team_b.drop('teamBName', axis=1, inplace=True)\n",
    "#     team_b.drop('teamBSeed', axis=1, inplace=True)\n",
    "    team_b.drop('School', axis=1, inplace=True)\n",
    "    team_b.drop('ID', axis=1, inplace=True)\n",
    "    team_b.drop('PersonalFouls', axis=1, inplace=True)\n",
    "        \n",
    "    return team_a, team_b\n",
    "    \n",
    "def getAllGames(years):\n",
    "    all_games = None\n",
    "    all_labels = None\n",
    "    for year in years:\n",
    "        data = pd.read_csv(\"./data/playoff/playoffdata\" + year + \".csv\")\n",
    "        playoff_data = swapGames(data.copy())\n",
    "        labels = calculateLabels(year, playoff_data)\n",
    "        \n",
    "        team_a = playoff_data.iloc[:, 1:3]\n",
    "        team_b = playoff_data.iloc[:, 3:5]\n",
    "        \n",
    "        team_a, team_b = getTeamInfos(team_a, team_b, year)\n",
    "        \n",
    "        diff_games = compareTeams(team_a, team_b)\n",
    "        \n",
    "        all_labels = labels if all_labels is None else pd.concat([all_labels, labels])\n",
    "        all_games = diff_games if all_games is None else pd.concat([all_games, diff_games])\n",
    "    \n",
    "    return all_games, all_labels\n",
    "\n",
    "\n",
    "def normalizeData(data): \n",
    "    updated_data = data.copy()\n",
    "    for col in data.columns:\n",
    "        rows = data[col].values\n",
    "        min_val = min(rows)\n",
    "        rows = (rows + abs(min_val))\n",
    "        updated_data.update(pd.DataFrame({col: rows}))\n",
    "    return updated_data\n",
    "\n",
    "\n",
    "def execute(model, x_train, y_train, x_test, y_test, epochs):\n",
    "    mse = list()\n",
    "    logloss = list()\n",
    "    score = list()\n",
    "    for i in range(epochs):\n",
    "        model.fit(x_train, y_train['winnerName'].tolist())\n",
    "        pred = model.predict(x_test)\n",
    "        pred_proba = model.predict_proba(x_test)\n",
    "        mse.append(mean_squared_error(y_test, pred))\n",
    "        logloss.append(log_loss(y_test, pred_proba))\n",
    "        score.append(model.score(x_test, y_test))\n",
    "#     print(\"MSE: \", mse)\n",
    "#     print(\"Log Loss for Proba: \", log_loss(y_test, pred_proba))\n",
    "#     print(\"Score:\", model.score(x_test, y_test))\n",
    "#     print('----------------------------------------')\n",
    "    return model, pred, mse, logloss, score\n",
    "\n",
    "\n",
    "def findWinners(predicted_labels, games):\n",
    "    team_a_names = games['teamAName'].values\n",
    "    team_b_names = games['teamBName'].values\n",
    "    team_a_seeds = games['teamASeed'].values\n",
    "    team_b_seeds = games['teamBSeed'].values\n",
    "    winners = list()\n",
    "    seeds = list()\n",
    "    for i in range(len(predicted_labels)):\n",
    "        winner = predicted_labels[i]\n",
    "        if winner == 1: \n",
    "            winners.append(team_a_names[i])\n",
    "            seeds.append(team_a_seeds[i])\n",
    "        elif winner == 0: \n",
    "            winners.append(team_b_names[i])\n",
    "            seeds.append(team_b_seeds[i])\n",
    "    return winners, seeds\n",
    "\n",
    "def makeGames(players, seeds):\n",
    "    if len(players) == 1: \n",
    "        pring(\"Champion is\", players[0])\n",
    "    elif len(players) % 2 != 0: \n",
    "        print(\"MISSING PLAYERS\")\n",
    "    else:\n",
    "        team_a = list()\n",
    "        team_a_seed = list()\n",
    "        team_b = list()\n",
    "        team_b_seed = list()\n",
    "        for i in range(len(players)): \n",
    "            if i % 2 == 0:\n",
    "                team_a.append(players[i])\n",
    "                team_a_seed.append(seeds[i])\n",
    "            else: \n",
    "                team_b.append(players[i])\n",
    "                team_b_seed.append(seeds[i])\n",
    "        games = pd.DataFrame({\n",
    "            'teamAName': team_a,\n",
    "            'teamASeed': team_a_seed, \n",
    "            'teamBName': team_b, \n",
    "            'teamBSeed': team_b_seed\n",
    "        })\n",
    "        return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1008 samples\n",
      "Epoch 1/100\n",
      "1008/1008 [==============================] - 1s 1ms/sample - loss: 0.6194 - accuracy: 0.7133\n",
      "Epoch 2/100\n",
      "1008/1008 [==============================] - 0s 118us/sample - loss: 0.5810 - accuracy: 0.7133\n",
      "Epoch 3/100\n",
      "1008/1008 [==============================] - 0s 122us/sample - loss: 0.5623 - accuracy: 0.7133\n",
      "Epoch 4/100\n",
      "1008/1008 [==============================] - 0s 123us/sample - loss: 0.5508 - accuracy: 0.7133\n",
      "Epoch 5/100\n",
      "1008/1008 [==============================] - 0s 132us/sample - loss: 0.5425 - accuracy: 0.7133\n",
      "Epoch 6/100\n",
      "1008/1008 [==============================] - 0s 177us/sample - loss: 0.5355 - accuracy: 0.7133\n",
      "Epoch 7/100\n",
      "1008/1008 [==============================] - 0s 139us/sample - loss: 0.5297 - accuracy: 0.7133\n",
      "Epoch 8/100\n",
      "1008/1008 [==============================] - 0s 125us/sample - loss: 0.5234 - accuracy: 0.7133\n",
      "Epoch 9/100\n",
      "1008/1008 [==============================] - 0s 111us/sample - loss: 0.5186 - accuracy: 0.7133\n",
      "Epoch 10/100\n",
      "1008/1008 [==============================] - 0s 116us/sample - loss: 0.5139 - accuracy: 0.7133\n",
      "Epoch 11/100\n",
      "1008/1008 [==============================] - 0s 116us/sample - loss: 0.5089 - accuracy: 0.7133\n",
      "Epoch 12/100\n",
      "1008/1008 [==============================] - 0s 113us/sample - loss: 0.5038 - accuracy: 0.7133\n",
      "Epoch 13/100\n",
      "1008/1008 [==============================] - 0s 119us/sample - loss: 0.4979 - accuracy: 0.7877\n",
      "Epoch 14/100\n",
      "1008/1008 [==============================] - 0s 124us/sample - loss: 0.4930 - accuracy: 0.8016\n",
      "Epoch 15/100\n",
      "1008/1008 [==============================] - 0s 112us/sample - loss: 0.4861 - accuracy: 0.8016\n",
      "Epoch 16/100\n",
      "1008/1008 [==============================] - 0s 111us/sample - loss: 0.4800 - accuracy: 0.8185\n",
      "Epoch 17/100\n",
      "1008/1008 [==============================] - 0s 108us/sample - loss: 0.4738 - accuracy: 0.8294\n",
      "Epoch 18/100\n",
      "1008/1008 [==============================] - 0s 114us/sample - loss: 0.4656 - accuracy: 0.8353\n",
      "Epoch 19/100\n",
      "1008/1008 [==============================] - 0s 107us/sample - loss: 0.4619 - accuracy: 0.8383\n",
      "Epoch 20/100\n",
      "1008/1008 [==============================] - 0s 113us/sample - loss: 0.4493 - accuracy: 0.8542\n",
      "Epoch 21/100\n",
      "1008/1008 [==============================] - 0s 115us/sample - loss: 0.4401 - accuracy: 0.8621\n",
      "Epoch 22/100\n",
      "1008/1008 [==============================] - 0s 111us/sample - loss: 0.4312 - accuracy: 0.8581\n",
      "Epoch 23/100\n",
      "1008/1008 [==============================] - 0s 123us/sample - loss: 0.4160 - accuracy: 0.8829\n",
      "Epoch 24/100\n",
      "1008/1008 [==============================] - 0s 118us/sample - loss: 0.4037 - accuracy: 0.8829\n",
      "Epoch 25/100\n",
      "1008/1008 [==============================] - 0s 120us/sample - loss: 0.3902 - accuracy: 0.8968\n",
      "Epoch 26/100\n",
      "1008/1008 [==============================] - 0s 106us/sample - loss: 0.3753 - accuracy: 0.9038\n",
      "Epoch 27/100\n",
      "1008/1008 [==============================] - 0s 106us/sample - loss: 0.3660 - accuracy: 0.9157\n",
      "Epoch 28/100\n",
      "1008/1008 [==============================] - 0s 121us/sample - loss: 0.3555 - accuracy: 0.9177\n",
      "Epoch 29/100\n",
      "1008/1008 [==============================] - 0s 120us/sample - loss: 0.3444 - accuracy: 0.9226\n",
      "Epoch 30/100\n",
      "1008/1008 [==============================] - 0s 112us/sample - loss: 0.3353 - accuracy: 0.9286\n",
      "Epoch 31/100\n",
      "1008/1008 [==============================] - 0s 110us/sample - loss: 0.3268 - accuracy: 0.9296\n",
      "Epoch 32/100\n",
      "1008/1008 [==============================] - 0s 106us/sample - loss: 0.3206 - accuracy: 0.9345\n",
      "Epoch 33/100\n",
      "1008/1008 [==============================] - 0s 112us/sample - loss: 0.3118 - accuracy: 0.9355\n",
      "Epoch 34/100\n",
      "1008/1008 [==============================] - 0s 121us/sample - loss: 0.3049 - accuracy: 0.9355\n",
      "Epoch 35/100\n",
      "1008/1008 [==============================] - 0s 121us/sample - loss: 0.3051 - accuracy: 0.9325\n",
      "Epoch 36/100\n",
      "1008/1008 [==============================] - 0s 120us/sample - loss: 0.3014 - accuracy: 0.9335\n",
      "Epoch 37/100\n",
      "1008/1008 [==============================] - 0s 108us/sample - loss: 0.2965 - accuracy: 0.9325\n",
      "Epoch 38/100\n",
      "1008/1008 [==============================] - 0s 120us/sample - loss: 0.2903 - accuracy: 0.9385\n",
      "Epoch 39/100\n",
      "1008/1008 [==============================] - 0s 109us/sample - loss: 0.2859 - accuracy: 0.9365\n",
      "Epoch 40/100\n",
      "1008/1008 [==============================] - 0s 108us/sample - loss: 0.2821 - accuracy: 0.9355\n",
      "Epoch 41/100\n",
      "1008/1008 [==============================] - 0s 103us/sample - loss: 0.2734 - accuracy: 0.9435\n",
      "Epoch 42/100\n",
      "1008/1008 [==============================] - 0s 112us/sample - loss: 0.2685 - accuracy: 0.9425\n",
      "Epoch 43/100\n",
      "1008/1008 [==============================] - 0s 113us/sample - loss: 0.2617 - accuracy: 0.9464\n",
      "Epoch 44/100\n",
      "1008/1008 [==============================] - 0s 113us/sample - loss: 0.2549 - accuracy: 0.9484\n",
      "Epoch 45/100\n",
      "1008/1008 [==============================] - 0s 115us/sample - loss: 0.2639 - accuracy: 0.9345\n",
      "Epoch 46/100\n",
      "1008/1008 [==============================] - 0s 120us/sample - loss: 0.2564 - accuracy: 0.9444\n",
      "Epoch 47/100\n",
      "1008/1008 [==============================] - 0s 143us/sample - loss: 0.2513 - accuracy: 0.9474\n",
      "Epoch 48/100\n",
      "1008/1008 [==============================] - 0s 113us/sample - loss: 0.2553 - accuracy: 0.9395\n",
      "Epoch 49/100\n",
      "1008/1008 [==============================] - 0s 115us/sample - loss: 0.2474 - accuracy: 0.9415\n",
      "Epoch 50/100\n",
      "1008/1008 [==============================] - 0s 108us/sample - loss: 0.2435 - accuracy: 0.9444\n",
      "Epoch 51/100\n",
      "1008/1008 [==============================] - 0s 111us/sample - loss: 0.2334 - accuracy: 0.9524\n",
      "Epoch 52/100\n",
      "1008/1008 [==============================] - 0s 130us/sample - loss: 0.2271 - accuracy: 0.9554\n",
      "Epoch 53/100\n",
      "1008/1008 [==============================] - 0s 131us/sample - loss: 0.2213 - accuracy: 0.9563\n",
      "Epoch 54/100\n",
      "1008/1008 [==============================] - 0s 106us/sample - loss: 0.2194 - accuracy: 0.9544\n",
      "Epoch 55/100\n",
      "1008/1008 [==============================] - 0s 123us/sample - loss: 0.2226 - accuracy: 0.9494\n",
      "Epoch 56/100\n",
      "1008/1008 [==============================] - 0s 128us/sample - loss: 0.2320 - accuracy: 0.9454\n",
      "Epoch 57/100\n",
      "1008/1008 [==============================] - 0s 119us/sample - loss: 0.2292 - accuracy: 0.9435\n",
      "Epoch 58/100\n",
      "1008/1008 [==============================] - 0s 115us/sample - loss: 0.2233 - accuracy: 0.9464\n",
      "Epoch 59/100\n",
      "1008/1008 [==============================] - 0s 120us/sample - loss: 0.2217 - accuracy: 0.9484\n",
      "Epoch 60/100\n",
      "1008/1008 [==============================] - 0s 111us/sample - loss: 0.2178 - accuracy: 0.9504\n",
      "Epoch 61/100\n",
      "1008/1008 [==============================] - 0s 119us/sample - loss: 0.2115 - accuracy: 0.9554\n",
      "Epoch 62/100\n",
      "1008/1008 [==============================] - 0s 127us/sample - loss: 0.2082 - accuracy: 0.9544\n",
      "Epoch 63/100\n",
      "1008/1008 [==============================] - 0s 122us/sample - loss: 0.2049 - accuracy: 0.9524\n",
      "Epoch 64/100\n",
      "1008/1008 [==============================] - 0s 120us/sample - loss: 0.2199 - accuracy: 0.9464\n",
      "Epoch 65/100\n",
      "1008/1008 [==============================] - 0s 108us/sample - loss: 0.2295 - accuracy: 0.9385\n",
      "Epoch 66/100\n",
      "1008/1008 [==============================] - 0s 109us/sample - loss: 0.2176 - accuracy: 0.9444\n",
      "Epoch 67/100\n",
      "1008/1008 [==============================] - 0s 110us/sample - loss: 0.2140 - accuracy: 0.9474\n",
      "Epoch 68/100\n",
      "1008/1008 [==============================] - 0s 109us/sample - loss: 0.2027 - accuracy: 0.9524\n",
      "Epoch 69/100\n",
      "1008/1008 [==============================] - 0s 111us/sample - loss: 0.2093 - accuracy: 0.9494\n",
      "Epoch 70/100\n",
      "1008/1008 [==============================] - 0s 114us/sample - loss: 0.2009 - accuracy: 0.9524\n",
      "Epoch 71/100\n",
      "1008/1008 [==============================] - 0s 117us/sample - loss: 0.2049 - accuracy: 0.9514\n",
      "Epoch 72/100\n",
      "1008/1008 [==============================] - 0s 109us/sample - loss: 0.2052 - accuracy: 0.9524\n",
      "Epoch 73/100\n",
      "1008/1008 [==============================] - 0s 121us/sample - loss: 0.1988 - accuracy: 0.9544\n",
      "Epoch 74/100\n",
      "1008/1008 [==============================] - 0s 108us/sample - loss: 0.2071 - accuracy: 0.9474\n",
      "Epoch 75/100\n",
      "1008/1008 [==============================] - 0s 114us/sample - loss: 0.2117 - accuracy: 0.9464\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 0s 118us/sample - loss: 0.2118 - accuracy: 0.9425\n",
      "Epoch 77/100\n",
      "1008/1008 [==============================] - 0s 105us/sample - loss: 0.2034 - accuracy: 0.9484\n",
      "Epoch 78/100\n",
      "1008/1008 [==============================] - 0s 99us/sample - loss: 0.2080 - accuracy: 0.9435\n",
      "Epoch 79/100\n",
      "1008/1008 [==============================] - 0s 107us/sample - loss: 0.2056 - accuracy: 0.9464\n",
      "Epoch 80/100\n",
      "1008/1008 [==============================] - 0s 104us/sample - loss: 0.2074 - accuracy: 0.9484\n",
      "Epoch 81/100\n",
      "1008/1008 [==============================] - 0s 108us/sample - loss: 0.1990 - accuracy: 0.9474\n",
      "Epoch 82/100\n",
      "1008/1008 [==============================] - 0s 117us/sample - loss: 0.1976 - accuracy: 0.9494\n",
      "Epoch 83/100\n",
      "1008/1008 [==============================] - 0s 146us/sample - loss: 0.1841 - accuracy: 0.9544\n",
      "Epoch 84/100\n",
      "1008/1008 [==============================] - 0s 143us/sample - loss: 0.1783 - accuracy: 0.9603\n",
      "Epoch 85/100\n",
      "1008/1008 [==============================] - 0s 142us/sample - loss: 0.1773 - accuracy: 0.9573\n",
      "Epoch 86/100\n",
      "1008/1008 [==============================] - 0s 155us/sample - loss: 0.1707 - accuracy: 0.9623\n",
      "Epoch 87/100\n",
      "1008/1008 [==============================] - 0s 143us/sample - loss: 0.1861 - accuracy: 0.9554\n",
      "Epoch 88/100\n",
      "1008/1008 [==============================] - 0s 147us/sample - loss: 0.1962 - accuracy: 0.9494\n",
      "Epoch 89/100\n",
      "1008/1008 [==============================] - 0s 143us/sample - loss: 0.1899 - accuracy: 0.9494\n",
      "Epoch 90/100\n",
      "1008/1008 [==============================] - 0s 146us/sample - loss: 0.1810 - accuracy: 0.9524\n",
      "Epoch 91/100\n",
      "1008/1008 [==============================] - 0s 143us/sample - loss: 0.1915 - accuracy: 0.9464\n",
      "Epoch 92/100\n",
      "1008/1008 [==============================] - 0s 146us/sample - loss: 0.1851 - accuracy: 0.9494\n",
      "Epoch 93/100\n",
      "1008/1008 [==============================] - 0s 150us/sample - loss: 0.1809 - accuracy: 0.9544\n",
      "Epoch 94/100\n",
      "1008/1008 [==============================] - 0s 143us/sample - loss: 0.1920 - accuracy: 0.9484\n",
      "Epoch 95/100\n",
      "1008/1008 [==============================] - 0s 149us/sample - loss: 0.1956 - accuracy: 0.9484\n",
      "Epoch 96/100\n",
      "1008/1008 [==============================] - 0s 115us/sample - loss: 0.1972 - accuracy: 0.9425\n",
      "Epoch 97/100\n",
      "1008/1008 [==============================] - 0s 109us/sample - loss: 0.1847 - accuracy: 0.9494\n",
      "Epoch 98/100\n",
      "1008/1008 [==============================] - 0s 110us/sample - loss: 0.1743 - accuracy: 0.9583\n",
      "Epoch 99/100\n",
      "1008/1008 [==============================] - 0s 107us/sample - loss: 0.1629 - accuracy: 0.9623\n",
      "Epoch 100/100\n",
      "1008/1008 [==============================] - 0s 87us/sample - loss: 0.1729 - accuracy: 0.9573\n",
      "189/1 - 0s - loss: 0.6104 - accuracy: 0.7619\n",
      "\n",
      "Test accuracy: 0.7619048\n",
      "\n",
      "Test loss: 0.6118477860455791\n"
     ]
    }
   ],
   "source": [
    "# Following https://www.tensorflow.org/tutorials/keras/classification\n",
    "\n",
    "# getting training and testing data \n",
    "x_train, y_train = getAllGames(train_years)\n",
    "x_test, y_test = getAllGames(test_years)\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='sigmoid'),\n",
    "    keras.layers.Dense(64, activation='sigmoid'),\n",
    "    keras.layers.Dense(16, activation='sigmoid'),\n",
    "    keras.layers.Dense(2, activation='sigmoid'),\n",
    "    keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# More model setup - Set optimizer, loss function, and metrics for model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "# Convert np array to tensor array\n",
    "tf_train_data = tf.convert_to_tensor(np.array(x_train), np.float32)\n",
    "tf_train_out =  tf.convert_to_tensor(np.array(y_train), np.float32)\n",
    "\n",
    "tf_test_data = tf.convert_to_tensor(np.array(x_test), np.float32)\n",
    "tf_test_out =  tf.convert_to_tensor(np.array(y_test), np.float32)\n",
    "\n",
    "# history is used to plot further down below\n",
    "history = model.fit(tf_train_data,\n",
    "                    tf_train_out, \n",
    "                    epochs=100)\n",
    "\n",
    "# Evaluating Accuracy\n",
    "test_loss, test_acc = model.evaluate(tf_test_data,  tf_test_out, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\nTest loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PREDICT\n",
      "['Villanova', 'Virginia Tech', 'West Virginia', 'Wichita State', 'Florida', 'Texas Tech', 'Arkansas', 'Purdue', 'Kansas', 'Seton Hall', 'Clemson', 'Auburn', 'Texas Christian', 'Michigan State', 'Rhode Island', 'Duke', 'Xavier', 'Missouri', 'Ohio State', 'Gonzaga', 'Houston', 'Michigan', 'Texas A&M', 'North Carolina', 'Virginia', 'Creighton', 'Kentucky', 'Arizona', 'Miami (FL)', 'Tennessee', 'Nevada', 'Cincinnati']\n",
      "------------------------------------\n",
      "['Villanova', 'West Virginia', 'Florida', 'Arkansas', 'Kansas', 'Clemson', 'Texas Christian', 'Rhode Island', 'Xavier', 'Ohio State', 'Houston', 'Texas A&M', 'Virginia', 'Kentucky', 'Miami (FL)', 'Nevada']\n",
      "16\n",
      "------------------------------------\n",
      "['Villanova', 'Florida', 'Kansas', 'Texas Christian', 'Xavier', 'Houston', 'Virginia', 'Miami (FL)']\n",
      "8\n",
      "------------------------------------\n",
      "['Villanova', 'Kansas', 'Xavier', 'Virginia']\n",
      "4\n",
      "------------------------------------\n",
      "['Villanova', 'Xavier']\n",
      "2\n",
      "------------------------------------\n",
      "['Villanova']\n",
      "1\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "# Need test data to make this work\n",
    "predictions = model.predict(tf_test_data)\n",
    "pred_labels = 1 - (np.argmax(predictions, axis=1))\n",
    "# print('\\nsklearn log loss:', log_loss(y_test, predictions))\n",
    "# print('\\nsklearn accuracy:', accuracy_score(y_test, pred_labels))\n",
    "\n",
    "data = pd.read_csv(\"./data/playoff/playoffdata\" + test_years[selected] + \".csv\")\n",
    "playoff_data = swapGames(data.copy())\n",
    "games = breakdownBracket(playoff_data)[0]\n",
    "winner_names, seeds = findWinners(pred_labels[:len(games)], games)\n",
    "\n",
    "print(\"\\n\\nPREDICT\")\n",
    "print(winner_names)\n",
    "print('------------------------------------')\n",
    "while (len(winner_names) > 1):\n",
    "    games = makeGames(winner_names, seeds)\n",
    "    team_a, team_b = getTeamInfos(games.iloc[:, :2], games.iloc[:, 2:], test_years[selected])\n",
    "    diff = compareTeams(team_a, team_b)\n",
    "    tfdiff = tf.convert_to_tensor(np.array(diff), np.float32)\n",
    "    pred = model.predict(tfdiff)\n",
    "    pred_labels = 1 - (np.argmax(pred, axis=1))\n",
    "    winner_names, seeds = findWinners(pred_labels, games)\n",
    "    print(winner_names)\n",
    "    print(len(winner_names))\n",
    "\n",
    "    print('------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL RESULT\n",
      "['Villanova' 'Alabama' 'West Virginia' 'Marshall' 'Florida' 'Texas Tech'\n",
      " 'Butler' 'Purdue' 'Kansas' 'Seton Hall' 'Clemson' 'Auburn' 'Syracuse'\n",
      " 'Michigan State' 'Rhode Island' 'Duke' 'Xavier' 'Florida State'\n",
      " 'Ohio State' 'Gonzaga' 'Houston' 'Michigan' 'Texas A&M' 'North Carolina'\n",
      " 'Maryland-Baltimore County' 'Kansas State' 'Kentucky' 'Buffalo'\n",
      " 'Loyola (IL)' 'Tennessee' 'Nevada' 'Cincinnati']\n",
      "----------\n",
      "['Villanova' 'West Virginia' 'Texas Tech' 'Purdue' 'Kansas' 'Clemson'\n",
      " 'Syracuse' 'Duke' 'Florida State' 'Gonzaga' 'Michigan' 'Texas A&M'\n",
      " 'Kansas State' 'Kentucky' 'Loyola (IL)' 'Nevada']\n",
      "----------\n",
      "['Villanova' 'Texas Tech' 'Kansas' 'Duke' 'Florida State' 'Michigan'\n",
      " 'Kansas State' 'Loyola (IL)']\n",
      "----------\n",
      "['Villanova' 'Kansas' 'Michigan' 'Loyola (IL)']\n",
      "----------\n",
      "['Villanova' 'Michigan']\n",
      "----------\n",
      "['Villanova']\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"ACTUAL RESULT\")\n",
    "results = pd.read_csv(\"./data/playoff/playoffdata\" + test_years[selected] + \".csv\")\n",
    "first, second, third, fourth, semi, final = breakdownBracket(results)\n",
    "print(first['winnerName'].values)\n",
    "print('----------')\n",
    "print(second['winnerName'].values)\n",
    "print('----------')\n",
    "print(third['winnerName'].values)\n",
    "print('----------')\n",
    "print(fourth['winnerName'].values)\n",
    "print('----------')\n",
    "print(semi['winnerName'].values)\n",
    "print('----------')\n",
    "print(final['winnerName'].values)\n",
    "print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZQU9bn/8ffDsCOLyogKKKhgRC4CjggqUZEoagJGvQpR486NyiJ6gxiNGtTrruiFw4kbGvGK4Iq7kbj9XBkUFUQUxGUAEVnCZoCB5/fHtwnN0DPMQNdUT9fndU6f6Vq66ikL++n6rubuiIhIctWKOwAREYmXEoGISMIpEYiIJJwSgYhIwikRiIgkXO24A6iq5s2be5s2beIOQ0SkRpk2bdpP7l6YaVuNSwRt2rShuLg47jBERGoUM/u2vG0qGhIRSTglAhGRhFMiEBFJOCUCEZGEUyIQEUk4JQIRkYRTIhARSTglAhGRhEtOIpgyBQ4+GBYsiDsSEZGckpxEUKcOfPQRTJ8edyQiIjklOYngoIPC308+iTcOEZEck5xE0LQptGmjRCAiUkZyEgFA585KBCIiZUSaCMysj5nNNrM5ZjainH1OM7PPzWymmf1flPFw7LEhGWzcGOlpRERqEnP3aA5sVgB8CfwKKAGmAgPc/fO0fdoBE4Fe7r7MzHZz9x8rOm5RUZFrGGoRkaoxs2nuXpRpW5RPBN2AOe7+tbuvAyYA/crscyEwxt2XAWwrCWRNaWm1nEZEpCaIMhG0BL5PWy5JrUvXHmhvZu+Y2ftm1ifCeIIOHWDo0MhPIyJSU0Q5Q5llWFe2HKo20A44CmgFvG1mHd19+RYHMhsIDATYa6+9diyq5s1VYSwikibKJ4ISoHXaciugbLfeEuBZd1/v7vOA2YTEsAV3v9fdi9y9qLAw45SblXfQQSERqMJYRASINhFMBdqZWVszqwv0ByaX2ecZ4GgAM2tOKCr6OsKYQiJYtQrmzYv0NCIiNUVkicDdS4FBwCvALGCiu880s5Fm1je12yvAEjP7HHgd+KO7L4kqJmBzD2MNNSEiAkRbR4C7vwi8WGbdNWnvHbgs9aoeHTvCkCHQtm21nVJEJJdFmghyUoMGcPfdcUchIpIzkjXExCbr1sHMmXFHISKSE5KZCO66KxQRLV4cdyQiIrFLZiI49tjwd9KkeOMQEckByUwEnTtDp04wblzckYiIxC6ZicAMzj0Xiothxoy4oxERiVUyEwHAGWdA7dowYULckYiIxCp5zUc3KSyEd9+FLl3ijkREJFbJTQQAhxwSdwQiIrFLbtHQJnfeCRddFHcUIiKxUSJYtAjuuw/mz487EhGRWCgR/OEPodL48svjjkREJBZKBG3bwlVXweOPw6uvxh2NiEi1UyIAGD4c2reHwYNhw4a4oxERqVbJbjW0Sb168NBDUFAQXiIiCaJEsEmPHpvfL1sGO+8cXywiItVIRUNl3XRTmMVs4cK4IxERqRZKBGX16QNLl8JvfgOrV8cdjYhI5JQIyurSJYw/9PHHYTwiVR6LSJ5TIsjk17+GUaPg2WdDPwMRkTymyuLyDB4cKo3bt487EhGRSCkRVOSaaza///BD6No19EIWEckjKhqqjLlz4YgjQgXy8uVxRyMiklVKBJWx774wejS89hoceijMnh13RCIiWaNEUFkDB8I//hHqDbp107hEIpI3lAiqomdPmDoV2rSBt96KOxoRkaxQzWdV7b13mOKyYcOwvGAB7LEHmMUbl4jIdtITwfZo1Ch88S9cGDqgnXlmKDISEamBlAh2RIsWMGgQTJwIHTvCSy/FHZGISJUpEeyIWrXgz3+GDz4Io5WecAKcfz6sXx93ZCIilaZEkA1du8K0aTBiBKxapU5nIlKjKBFkS716YQjrCRNC/cGXX8IFF8CKFXFHJiJSISWCbNvUeujdd2HcOOjcObwXEclRSgRROeccePvt8L5nT7j2WigtjTUkEZFMlAiidNhhMH06nHUWjBwZhrYWEckxkSYCM+tjZrPNbI6Zjciw/RwzW2xm01OvC6KMJxZNmsBDD8HTT8Mll4R1a9bEGpKISLrIEoGZFQBjgOOBDsAAM+uQYdfH3b1z6nV/VPHE7qSToEGD0PGsS5dQVLRxY9xRiYhE+kTQDZjj7l+7+zpgAtAvwvPVDA0bwuGHh6Ki00/X04GIxC7KRNAS+D5tuSS1rqxTzOxTM3vCzFpnOpCZDTSzYjMrXrx4cRSxVp969eCBB+D22+HJJ0NSmDkz7qhEJMGiTASZRmHzMsvPAW3cvRPwGvBwpgO5+73uXuTuRYWFhVkOMwZmcPnl8PzzMH9+eC8iEpMou8CWAOm/8FsBC9J3cPclaYv3AbdEGE/uOeEEmDED1q4NyytXwoYN0KxZvHGJSKJE+UQwFWhnZm3NrC7QH5icvoOZ7ZG22BeYFWE8uWm33aB1a3CHk0+GY46BpUvjjkpEEiSyRODupcAg4BXCF/xEd59pZiPNrG9qtyFmNtPMPgGGAOdEFU/OM4Nhw0J9Qa9eUNPrQkSkxjD3ssX2ua2oqMiLi4vjDiM6r74K/fqFeZJfeik8LYiI7CAzm+buRZm2qWdxrjn2WHjxRfj+ezjttFBkJCISIY2XnIuOPnrzQHVmIRloKkwRiYgSQa468MDw1x0GD4b99oNLL403JhHJSyoaynWlpWFu5GHDYOjQ0LxURCSLlAhyXZ06YU7kYcPgnntCE9N//SvuqEQkjygR1AQFBXDnnSERTJ4cZj4TEckS1RHUJIMHhxFL998/7khEJI8oEdQ0Q4dufj9/PrTMNI6fiEjlqWiopnrmmdDp7LrrYMWKuKMRkRpMiaCmOvpo6NsX/vIXaNsWbr0V1q+POyoRqYGUCGqqpk1Da6Jp0+DQQ+GKK0JSEBGpIiWCmq5r1zAkxYgRcMghcUcjIjWQKovzxU03xR2BiNRQeiLIJz//DNdfDx9+GHckIlKDKBHkk9JSGDMm9ELWqKUiUklKBPmkcWO44YYwcun48XFHIyI1hBJBvjn3XDjsMLjoIpiVvJk/RaTqlAjyTUFBaFbasCGceaaKiERkm9RqKB+1bAlPPhmKijShjYhsgxJBvurZc/P7WbPggAPii0VEcpqKhvLdAw/Af/wHvP563JGISI5SIsh3p50G7duHv99+G3c0IpKDlAjyXePGYaTS9evD7GY//xx3RCKSY5QIkqB9e3j0Ufj4Y7jyyrijEZEco8ripDjxRLj22jBktYhIGiWCJLn22rgjEJEcpKKhpFm9GkaPhlWr4o5ERHKEEkHSfPYZDB4M998fdyQikiOUCJKme3f45S/hzjs1taWIAEoEyXTFFfD99/DYY3FHIiI5QIkgiY4/Hg46KMxx/K9/xR2NiMRMiSCJzOCOO6BFC1i8OO5oRCRmaj6aVMccA716aXRSEancE4GZ7Wtm9VLvjzKzIWbWLNrQJHJmsGgRPPhg3JGISIwqWzT0JLDBzPYDHgDaAv+3rQ+ZWR8zm21mc8xsRAX7nWpmbmZFlYxHsmX0aDj/fPjgg7gjEZGYVDYRbHT3UuC3wCh3HwbsUdEHzKwAGAMcD3QABphZhwz7NQaGAPomisPw4bD77prwXiTBKpsI1pvZAOBs4PnUujrb+Ew3YI67f+3u64AJQL8M+10P3Aqo+UocGjeGkSPhvffguefijkZEYlDZRHAu0AO40d3nmVlbYPw2PtMS+D5tuSS17t/MrAvQ2t2fpwJmNtDMis2seLFauWTfuedCu3Zw1VWwYUPc0YhINatUInD3z919iLs/ZmY7A43d/eZtfCxTc5R/lz2YWS3gLuDySpz/XncvcveiwsLCyoQsVVG7Ntx4I3TqpDGIRBKosq2G3jCzJma2C/AJMM7M7tzGx0qA1mnLrYAFacuNgY7AG2b2DdAdmKwK45j853+GOQuaNo07EhGpZpUtGmrq7iuAk4Fx7n4w0Hsbn5kKtDOztmZWF+gPTN600d3/6e7N3b2Nu7cB3gf6untxla9CsueTT+DFF+OOQkSqUWUTQW0z2wM4jc2VxRVKtTIaBLwCzAImuvtMMxtpZn23K1qJ3tChcMEFsHZt3JGISDWpbCIYSfhCn+vuU81sH+CrbX3I3V909/buvq+735had427T86w71F6GsgBV18NCxfCww/HHYmIVBPzGtZ2vKioyIuLlS8i4w6HHgpLlsDs2aEiWURqPDOb5u4Z62ArW1ncysyeNrMfzWyRmT1pZq2yG6bkBLPQjPTrr2HixLijEZFqUNmioXGEit49CX0Bnkutk3z0m99Ajx6wdGnckYhINajsc3+hu6d/8T9kZpdGEZDkgFq14J13NDKpSEJU9ongJzM708wKUq8zgSVRBiYxMwv1Bf/4B5SWxh2NiESosongPELT0R+AhcCphGEnJJ+9+mqYt+Dqq+OOREQiVNkhJr5z977uXujuu7n7SYTOZZLPjjsO/uu/4JZb4PlKdR8RkRpoR6aqvCxrUUjuGjUKunSB3/8evvkm7mhEJAI7kghUk5gE9evDpElhVNLTT9fopCJ5aEd6C9Wsnmiy/fbdFx55JFQeFxTEHY2IZFmFicDMVpL5C9+ABpFEJLmpb9rwUKWl6nEskkcqLBpy98bu3iTDq7G765sgicaODUNQaFA6kbyxI3UEkkRt2sBHH8G118YdiYhkiRKBVM3xx8OFF8Jtt8HUqXFHIyJZoEQgVXfbbbD77mHegvXr445GRHaQEoFUXdOmMGYMzJgBb78ddzQisoNU4Svb56ST4MsvQ9NSEanR9EQg229TEiguho0b441FRLabEoHsmLfegkMOgVtvjTsSEdlOSgSyY3r2hP79w6xmr70WdzQish2UCGTHmMF998EBB8CAAfDdd3FHJCJVpEQgO26nneCpp0Jv41NP1UQ2IjWMWg1JdrRvDw8/DIsWaRwikRpG/8dK9vz2t5vfL1kCu+4aXywiUmkqGpLse/99aNsWnnsu7khEpBKUCCT7OnUKRUW/+x28+27c0YjINigRSPY1bAjPPhvGI+rVCx5/PO6IRKQCSgQSjZYt4b33oKgo9DN4/fW4IxKRcqiyWKLTvHnoZHb//XDkkXFHIyLl0BOBRKt+fRg0CGrVCp3N3nwz7ohEpAwlAqk+F1wA/frBV1/FHYmIpFEikOpz772hs9lJJ8HKlXFHIyIpSgRSfdq0CS2IZs+GE09UMhDJEUoEUr2OOQYefTT0L7j66rijEREibjVkZn2Au4EC4H53v7nM9j8AlwAbgFXAQHf/PMqYJAecfnpoUdStW1h++mlYtgx+/jkMa92pU7zxiSSMuXs0BzYrAL4EfgWUAFOBAelf9GbWxN1XpN73BS529z4VHbeoqMiLi4sjiVli0ro1lJRsXh4wAEaOhP32iy8mkTxjZtPcvSjTtiiLhroBc9z9a3dfB0wA+qXvsCkJpDQCoslKktveeAO++Qa+/RauvBKeeUaT3IhUoyiLhloC36ctlwCHlt3JzC4BLgPqAr0ijEdy1aa5jwH+539g8OBQdATw/PNhqIqijD9kRCQLonwisAzrtvrF7+5j3H1f4AogY+2hmQ00s2IzK168eHGWw5Scs8ceUKcObNwYnhC6d4ebboKIijFFki7KRFACtE5bbgUsqGD/CcBJmTa4+73uXuTuRYWFhVkMUXJarVrw1lth1rM//QkGDtTsZyIRiDIRTAXamVlbM6sL9Acmp+9gZu3SFk8E1OVUtrTzzvDYY3DVVWHMor59w5SYIpI1kdURuHupmQ0CXiE0H33Q3Wea2Uig2N0nA4PMrDewHlgGnB1VPFKDmcENN8Bee8GMGVC3btwRieSVyJqPRkXNRwWADz8MQ1bcfPPmimURKVdczUdFolNcDA8/DO3ahYrk1avjjkikxlIikJrp4ovh44/h8MNDRfJ++8G4cXFHJVIjKRFIzdWxY+hn8PbboS/CDz/EHZFIjaQZyqTmO+KIkAws1XVl48bQ9FREKkX/t0h+2JQE3nwTunTR04FIFSgRSH5p2hTmzAkzoS1cGHc0IjWCEoHkl86dw3wHn30W6hAmTYo7IpGcp0Qg+eekk0KLon33hdNOgxdfjDsikZymymLJT/vvD++8A+PHQ58Kp7gQSTw9EUj+qlMHzj03tCCaOzfMjLZixdb7rVoFN94I8+dXf4wiOUCJQJJhxgx46in41a/CtJibuMMFF4T5k3v3hh9/jC9GkZgoEUgy9OsHTzwB06dDr16waV6LUaPg8cfh7LPD08J338Ubp0gMlAgkOfr1g8mT4Ysv4KijwtSYo0fDb38bhqeYO3fzTGjr18caqkh1UiKQZDnuOHjpJWjZEnbZBT74ICQBM6hfP+xzyy2h6em0aVt/ft266o1XpBooEUjyHHUUvPIKNG4chrBu2nTL7d27w5o10KMHXH99qGT+5htYsGBzPwWRPKJEIMlkmabUTjnySPjkE/j1r+Gaa+CFF0Ldwi67QIsWcM458Oqr1RaqSNSUCEQy2WUXePLJ8OQwZ07opFa/PjzzDBx4IJx8cphPWSQPKBGIlMcMjj0Wdt9987qmTUMdQ4sW4cnhb3+LLz6RLFHPYpGq2mOPUFR0111w4olhnXvFxU0iOUxPBCLbo3HjUH+w666hIrlbN3j33bijEtkuSgQiO2qXXeCnn+Css2DlyrijEakyJQKRHdWkSagrmDcPhg2LOxqRKlMiEMmGnj1hxAh44AF4+um4oxGpEiUCkWy57jo4+GAYOzZUHlfVRx+FZqnjxoURUUWqiRKBSLbUrRualk6YEFoQVXU4iqVLw9PEeeeFJqsXXghLlkQTq0gaJQKRbCosDJXHa9eGPgjDh8OGDZX7bO/eYd933oH+/UO9wzHHVP7zVfHee3DxxfDzz9k/ttQ4SgQiUSgogA4d4Lbbwqin//xn+fveeSfcdBNs3Bgm0TnsMLj/fnjjDbjhhnCsbFq6NCSal1+Gzz+HP/4xnFsSS4lAJAq1a8OYMeH1yithILtZs7bcZ82aMAz28OFhjuWyHdJ69AjjHUGodygqgsGDQ9HT9v6Sdw+zti1cCBMnhgl7br8dHnpo+44neUGJQCQqZqH45e9/DxPhXHxxWO8efunvtVf4Yu/RIzwBlNcz2T38im/SBB58EAYMgPbt4eGHqx7T//5vmJPhtttCYjnrrPAEcsUVW87cJolivj2tG2JUVFTkxcXFcYchUjUlJWEinMMPD8VEhYVwwglw+eVwxBGVH56itBTefBP+9KeQDB55pPIxrFsHrVqFBPDCC5vPOX16aO10xhnw179CgwZVvz7JeWY2zd2LMm3TWEMi1aFVq/CCMIrpt9+GMYuqqnbtUIH8/vuwenVYN3t2GObiuOMq/mzduqGJ6vr1Wyaezp1D8dTNN8MBB8CVV1Y9LqnRVDQkUt3q1du+JJDODHbaKby/8spQl1BRUdGmJ/9WraBt262333RTqJy+6KKwvGDB5kQTFffwhLN2bbTnkW1SIhCp6R56KMy6ds45oSL4iy+23mfs2PAksWJF+cc58kho1izUZ3ToACNHRhPv88/DPvuEFlJ16oQnpEGDojmXVIoSgUhN16RJKPO/7LLQoqhDhy0nzSktDZXDa9aEUVO3pbAQTj0V7rgDPv108/qxY6FLlzBRz/YqLQ0V040ahdFbr78+PIUMGbL1vp99lvlca9dqcL9sc/ca9Tr44INdRMqxaJH7zTe7r18flsePdx861B3cJ0+u/HGWLHEvLHQ/9FD30lL3jz8OxzBz339/96VLt9x/3Tr3n35y//pr96++ct+4ccvtCxaEfdzd581zX7t263Nu3Oj+6afuq1a5DxsWzlVcHLZ99pn7dde5H3OMe/36IbY5cyp/PeJAsZfzvRrplzbQB5gNzAFGZNh+GfA58CkwBdh7W8dUIhCppI0b3bt1C/+bd+zovmFD1T4/fnz47JgxYfmFF9ynTHGvU8e9d+/NX/5DhoR1odTfvVEj97lzNx9n6dKQPPr3r/h8d9wRjrP33uE4Awe6r1gRtl14YVjXqZP74MHuO+8c1kmlxZIIgAJgLrAPUBf4BOhQZp+jgYap9xcBj2/ruEoEIlWwfr3700+7z5pV9c9u3Oh+7LHuo0dvuX7cOPc99wxf9rff7l6rlvt557nffXfY9s47m/ddvdr9qKPc69Z1f/vtis+3dKl7hw7u7dq5v/nmlttWrw5PKZvMmJH5qULKVVEiiKwfgZn1AK5z9+NSy1emiqJuKmf/LsBodz+8ouOqH4FINVqyJPR67t17y/UrV4b6hn/9C+bOhQMP3PqzY8bAn/8cOqqNHx/6KWzL+vVhSI1alay+/OknuOeeUBHetWvl6kASqqJ+BFFWFrcEvk9bLkmtK8/5wEuZNpjZQDMrNrPixYsXZzFEEanQrrtunQRg8xdu/fqZkwBAixYhUYwcWbkkAKEVUWWTAIQms9dfH1pNNW0Kv/xldobwnjMnmuazS5bAc8+FCvPzzgv/fXJAlIkgU1fJjI8fZnYmUATclmm7u9/r7kXuXlRYWJjFEEUkMqeeCsuXh6eCqFx+OfzwQ2g1NWIEvP02jBq1Y8ecNi10rOveHebPz06c06aFwQebN4e+feHWW0Mv83r1snP8HRRlz+ISoHXacitgQdmdzKw3cBVwpLurZ4lIPqlbN/pztGgRhus44YQwimr37tt/rDVr4Mwzw5PQt9+GcaBefjk0yS1r6dLw9NKs2baPO3JkSFJXXRWGJz/kkJwayiPKRDAVaGdmbYH5QH/gd+k7pOoF/gr0cfcfI4xFRJLg5pt37PMbNsChh4Zk0Lx56KSX6Vf7ypXhy3z5cnjttdC/oqzS0jC+U8OGYZTZpk1Dn490I0fCokWhPiVGkRUNuXspMAh4BZgFTHT3mWY20sz6pna7DdgJmGRm081sclTxiEhCLFsWiolKSqr+2caNQ0/t3r3DGEwffwz77hsaxqZ3YqtbN1ROL10aemRPmbL1se66Czp2DD21W7feOglAOObYsWEMqDiV15woV19qPioiFZo3L/RHqEo/g1Wr3I87LnRcy+TSS927dnVfs2bL9SUloY9GnTruTz65ef3cue4NGrj367d157p0y5e7N28emthWtF8WUEHzUQ0xISL5pU2bMGzFgw+GZquV8cADYQKh5cszb+/VK/xqP+cc6NkzTCcK0LJlGM6jR4/NgwC6wx/+EEaKHT264iHGmzYNxUNvvFH5WKNQXobI1ZeeCERkm5YtC7+ywf2//zsMk1Gedevc99rL/YgjKj7mX/4SjldQ4P7hh1tuS++1ffLJYb+yHfHKU1oazl1YuPUTRxZRwROB5iMQkfzTrBm8+ipceik8+miYl3m33WDq1PDEkN4MfeJE+O678Ou9IldfHZ4Y2rcPFcXpNvV9cIc99wyzyG0a0ntbCgpCf4iVK2NrSaQZykQkvy1eHL74N2wIo56uWxdaFw0fHr64O3cOLXw++6xqndmiUlKyeRKjLIqrZ7GISPw2/fp3h2efhVNOCT17hw8PQ1qcfXbonZwLSWDUKPjFL2DevGo9bQ5cuYhINahdO0zn+fjjcPHFYY6GSy6BYcPg5JPjji445ZRQuXzxxZtnlYNQOX3FFZHN5qZEICLJUqtWqA+45prQEayiVj3VrXVruOGG0Jt50qSwbsWK0MFt0qTIEoHqCEREcsmm3s3z58OsWWH2tkcfDUNUHHbYdh9WdQQiIjVFQQH89a+hUnv8eHjkkdBiaQeSwLao+aiISK45+ODQpLVRo/C+KOMP+axRIhARyUWNGoW/PXpEfioVDYmIJJwSgYhIwikRiIgknBKBiEjCKRGIiCScEoGISMIpEYiIJJwSgYhIwikRiIgkXI0bdM7MFgPfVuEjzYGfIgonlyXxupN4zZDM607iNcOOXffe7l6YaUONSwRVZWbF5Y24l8+SeN1JvGZI5nUn8ZohuutW0ZCISMIpEYiIJFwSEsG9cQcQkyRedxKvGZJ53Um8ZojouvO+jkBERCqWhCcCERGpgBKBiEjC5XUiMLM+ZjbbzOaY2Yi444mCmbU2s9fNbJaZzTSzoan1u5jZ383sq9TfneOONdvMrMDMPjaz51PLbc3sg9Q1P25mdeOOMdvMrJmZPWFmX6TueY+E3OthqX/fM8zsMTOrn2/328weNLMfzWxG2rqM99aCe1LfbZ+aWdcdOXfeJgIzKwDGAMcDHYABZtYh3qgiUQpc7u4HAN2BS1LXOQKY4u7tgCmp5XwzFJiVtnwLcFfqmpcB58cSVbTuBl52918ABxGuP6/vtZm1BIYARe7eESgA+pN/9/shoE+ZdeXd2+OBdqnXQGDsjpw4bxMB0A2Y4+5fu/s6YALQL+aYss7dF7r7R6n3KwlfDC0J1/pwareHgZPiiTAaZtYKOBG4P7VsQC/gidQu+XjNTYBfAg8AuPs6d19Ont/rlNpAAzOrDTQEFpJn99vd3wKWllld3r3tB/zNg/eBZma2x/aeO58TQUvg+7TlktS6vGVmbYAuwAdAC3dfCCFZALvFF1kkRgHDgY2p5V2B5e5emlrOx/u9D7AYGJcqErvfzBqR5/fa3ecDtwPfERLAP4Fp5P/9hvLvbVa/3/I5EViGdXnbVtbMdgKeBC519xVxxxMlM/s18KO7T0tfnWHXfLvftYGuwFh37wKsJs+KgTJJlYv3A9oCewKNCEUjZeXb/a5IVv+953MiKAFapy23AhbEFEukzKwOIQk86u5PpVYv2vSomPr7Y1zxReBwoK+ZfUMo8utFeEJolio6gPy83yVAibt/kFp+gpAY8vleA/QG5rn7YndfDzwFHEb+328o/95m9fstnxPBVKBdqmVBXULl0uSYY8q6VNn4A8Asd78zbdNk4OzU+7OBZ6s7tqi4+5Xu3srd2xDu6z/c/QzgdeDU1G55dc0A7v4D8L2Z7Z9adQzwOXl8r1O+A7qbWcPUv/dN153X9zulvHs7Gfh9qvVQd+Cfm4qQtou75+0LOAH4EpgLXBV3PBFd4xGER8JPgemp1wmEMvMpwFepv7vEHWtE138U8Hzq/T7Ah8AcYBJQL+74IrjezkBx6n4/A+ychHsN/AX4ApgBPBeI9z8AAAHRSURBVALUy7f7DTxGqANZT/jFf35595ZQNDQm9d32GaFF1XafW0NMiIgkXD4XDYmISCUoEYiIJJwSgYhIwikRiIgknBKBiEjCKRGIlGFmG8xsetora713zaxN+uiSIrmg9rZ3EUmcn929c9xBiFQXPRGIVJKZfWNmt5jZh6nXfqn1e5vZlNS48FPMbK/U+hZm9rSZfZJ6HZY6VIGZ3ZcaX/9VM2sQ20WJoEQgkkmDMkVDp6dtW+Hu3YDRhPGNSL3/m7t3Ah4F7kmtvwd4090PIowJNDO1vh0wxt0PBJYDp0R8PSIVUs9ikTLMbJW775Rh/TdAL3f/OjXQ3w/uvquZ/QTs4e7rU+sXuntzM1sMtHL3tWnHaAP83cNEI5jZFUAdd78h+isTyUxPBCJV4+W8L2+fTNamvd+A6uokZkoEIlVzetrf91Lv3yWMggpwBvD/Uu+nABfBv+dXblJdQYpUhX6JiGytgZlNT1t+2d03NSGtZ2YfEH5EDUitGwI8aGZ/JMwgdm5q/VDgXjM7n/DL/yLC6JIiOUV1BCKVlKojKHL3n+KORSSbVDQkIpJweiIQEUk4PRGIiCScEoGISMIpEYiIJJwSgYhIwikRiIgk3P8H2XlITmbMRDsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "\n",
    "training_loss = history.history['loss']\n",
    "\n",
    "# # Only plotting every 5 epochs\n",
    "# training_loss = training_loss[::5]\n",
    "# epoch_count = range(1, 101, 5)\n",
    "\n",
    "epoch_count = range(1, 101)\n",
    "\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
